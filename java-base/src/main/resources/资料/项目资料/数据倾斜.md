# hive、Spark、Flink如何处理数据倾斜

数据倾斜是指在分布式计算中，某些Key或分区的数据量远大于其他分区，导致

少数Task的处理时间特别长。资源利用不平衡。作业整体被拖慢，导致OOM。



####  **Hive**

(批处理，基于 MapReduce)    Hive 的数据倾斜通常发生在 **Group By**、**Join** 和 **窗口函数** 等场景。

方法一：开启Hive自动倾斜处理。

- `hive.map.aggr = true`：在 Map 端进行部分聚合，减少 Reduce 输入。

- `hive.groupby.skewindata = true`：**经典方法**。当数据倾斜时，会启动两个 MapReduce 作业。

  1. 第一个 MR 随机分发键（给 Key 加随机前缀），进行分散的聚合，使负载均衡。

  2. 第二个 MR 再按原始 Key 进行最终聚合。

     

方法二：拆分热点 key（最常用）

如果大 Key 可识别（`NULL` 或特定值），将其单独处理再 `UNION ALL`。

```
SELECT * FROM A JOIN B ON (A.key = B.key) WHERE A.key IS NOT NULL
UNION ALL
SELECT * FROM A WHERE A.key IS NULL JOIN B ON (1=1) -- 处理NULL值
```

适合**明确知道哪些是热点 key** 的场景



方法三：Map Join（小表广播）

小表直接加载到内存

避免 shuffle，**从根源消除倾斜**



方法四：随机前缀（两阶段聚合）

将随机数作为 Join Key：对大 Key 添加随机前缀，对小表进行扩容，分散压力。

```mysql
-- 第一阶段打散 key
select concat(key, '_', rand()) as new_key, sum(val)
group by concat(key, '_', rand());
-- 第二阶段聚合
select split(new_key,'_')[0], sum(val)
group by split(new_key,'_')[0];
```

#### **Spark**

spark 的数据倾斜发生在 **Shuffle** 阶段（如 `groupByKey`, `reduceByKey`, `join`）。

参数调整、算子调优

- `spark.sql.adaptive.enabled = true`（Spark 3.x 默认开启）：开启自适应查询执行，可以动态调整分区数量。
- 增加 Shuffle 分区数：`spark.sql.shuffle.partitions`，让数据分散到更多 Task。
- **使用 `reduceByKey` 替代 `groupByKey`**：先在 Map 端合并，减少传输。
- **使用 `mapJoin`**：同 Hive，通过 `broadcast` 函数实现。

**两阶段聚合（加盐/加前缀）：**

- 给倾斜的 Key 添加随机前缀（如 0-9），先进行局部聚合。
- 去掉前缀，再进行全局聚合。

**分离倾斜Key**

- 通过采样找出导致倾斜的 Key。
- 将数据集拆分为包含倾斜 Key 和不包含倾斜 Key 两部分，分别处理后再合并。
- 

#### **Flink**

Flink 的数据倾斜主要体现在 **KeyBy** 后的窗口或聚合操作，导致单个 SubTask 负载过高。

**常用解决方案：**

- **Rebalance / Rescale：**
  - 在 KeyBy 之前使用 `rebalance()` 算子，强制进行数据重分布，可以缓解源数据不均匀带来的倾斜。
- **本地聚合（预聚合）：**
  - 在窗口聚合前，使用 `reduce` 或 `aggregate` 函数进行增量聚合，减少状态大小和 Shuffle 数据量。
- **自定义分区器：**
  - 实现 `Partitioner` 接口，自定义数据分发逻辑，避免热点 Key 全部分到同一个分区。
- **Key 拆分（加盐）：**
  - 与 Spark 思路类似，为原始 Key 添加随机后缀，将一个大 Key 拆分为多个小 Key，先进行聚合，最后再合并。
  - 对于 `COUNT DISTINCT` 场景非常有效。
- **状态后端与检查点优化：**
  - 数据倾斜会导致状态倾斜，单个 TaskManager 的状态可能非常大。可以考虑使用 RocksDB 状态后端，并优化检查点配置（如异步快照、增量检查点）。

# 如何进行任务优化

 

#### **1. Hive 任务优化**

- **执行引擎**：考虑使用  Spark 作为执行引擎，替代 MapReduce。
- **存储格式**：使用列式存储(ORC)，并启用压缩（Snappy）。
- **分区与分桶**：对表进行合理的**分区**和**分桶**.
- **向量化查询**：`set hive.vectorized.execution.enabled = true;` 对 ORC 格式性能提升显著。
- **CBO（成本优化器）**：`set hive.cbo.enable=true;` 让 Hive 选择更优的执行计划。
- **小文件合并**：避免 Map 数过多，使用 `CombineHiveInputFormat`，或 `distribute by` 控制 Reduce 输出文件数。

#### **2. Spark 任务优化**

- **资源调优**：
  - 合理设置 `executor-memory`, `executor-cores`, `num-executors`。
  - 调节 `spark.memory.fraction` 和 `spark.memory.storageFraction` 优化内存模型。
- **并行度**：设置合适的并行度（`spark.default.parallelism`），一般为 `cores * 2 ~ 3`。
- **数据本地性**：确保输入数据在 HDFS 的块位置与 Executor 启动位置一致。
- **Shuffle 优化**：
  - 调节 `spark.shuffle.file.buffer`（写缓冲区），`spark.reducer.maxSizeInFlight`（读缓冲区）。
- **Broadcast & Cache**：对小数据集和重复使用的 RDD/DataFrame 进行广播或缓存。
- **AQE（自适应查询执行）**：**Spark 3.x 的核心优化**。
  - `spark.sql.adaptive.enabled=true`
  - 可自动：合并 Shuffle 分区、动态切换 Join 策略、动态优化倾斜 Join（`spark.sql.adaptive.skewJoin.enabled`）。

#### **3. Flink 任务优化**

- **资源配置**：合理设置 TaskManager 的 `taskmanager.memory.process.size`、`taskmanager.numberOfTaskSlots` 和 JobManager 的资源。
- **并行度**：设置算子链（`chain`）和并行度，避免数据在同一个线程内传递导致无法并行。
- **状态管理**：
  - 选择合适的状态后端（`HashMapStateBackend` 或 `RocksDBStateBackend`）。
  - 设置合理的状态 TTL，及时清理无用状态。
- **检查点与容错**：
  - 设置合适的检查点间隔（`execution.checkpointing.interval`）。
  - 对齐（Barrier）时间可能成为瓶颈，可考虑使用**非对齐检查点**（Flink 1.11+）处理反压严重的情况。
- **反压监控**：通过 Web UI 或 Metrics 定位反压来源的算子，通常是数据倾斜或处理逻辑瓶颈的体现。
- **窗口优化**：
  - 使用 `Sliding`、`Tumbling` 等预定义窗口。
  - 对于大窗口，考虑使用 `ProcessFunction` 手动管理状态，减少状态开销。
- **网络缓冲**：调节 `taskmanager.memory.network.fraction` 等网络缓冲区参数。

### **总结与对比**

| 特性             | Hive                                   | Spark                                 | Flink                               |
| :--------------- | :------------------------------------- | :------------------------------------ | :---------------------------------- |
| **处理范式**     | 批处理（SQL）                          | **批处理为主**，微批流                | **流处理为首位**，真正流式          |
| **倾斜处理重点** | **Join** 和 **Group By**               | **Shuffle 算子**                      | **KeyBy 后的窗口/聚合**             |
| **核心优化手段** | **`skewindata`参数**、SQL改写、MapJoin | **AQE（Spark 3+）**、广播、两阶段聚合 | **本地聚合**、Key拆分、状态后端优化 |